Given a non-empty string s and a dictionary wordDict containing a list of non-empty words, determine if s can be segmented into a space-separated sequence of one or more dictionary words. You may assume the dictionary does not contain duplicate words.

For example, given
s = "leetcode",
dict = ["leet", "code"].

Return true because "leetcode" can be segmented as "leet code".
 
# Solution
 
##### Solution one : Time Limit Exceede

The most intuitive solution is to use backtracking.
  
```cpp
class Solution {
public:
    bool wordBreak(string s, vector<string>& wordDict) {
        std::unordered_set<std::string> word_set(wordDict.begin(), wordDict.end());
        return backtracking(s, 0, word_set);
    } 
private:
    bool backtracking(const std::string &s, 
                      std::size_t position, 
                      std::unordered_set<std::string> &word_set) {
        if (position == s.size()) {
            return true;
        } else {
            for (std::size_t len = s.size() - position; len > 0; --len) {
                if (word_set.count(s.substr(position, len)) > 0
                   && backtracking(s, position + len, word_set)) {
                    return true;
                }
            }
            return false;
        }
    }
};
```
  

##### Solution two

Use dynamic programming here, by breaking down the original problem into sub-problems and solve subproblems just once and stores their solutions.

Not that although dynamic programming algorithms are often used for optimization, it does not mean it can be only used for optimization problems. This problem, for example, has nothing to do with optimization. 

```cpp
class Solution {
public:
    bool wordBreak(string s, vector<string>& wordDict) {
        std::unordered_set<std::string> word_set(wordDict.begin(), wordDict.end());
        std::vector<bool> is_breakable(s.size() + 1, false);
        is_breakable[0] = true;
        
        for (std::size_t end = 1, s_size = s.size(); end <= s_size; ++ end) {
            for (std::size_t start = 0; start < end; ++ start) {
                if (is_breakable[start] && word_set.count(s.substr(start, end - start)) > 0) {
                    is_breakable[end] = true;
                    break; // already breakable
                }
            }
        }
        
        return is_breakable[s.size()];
    } 

};
```

Maybe this style is easier to understand.

```cpp
class Solution {
public:
    bool wordBreak(string s, vector<string>& wordDict) {
        unordered_set<string> wordset(wordDict.begin(), wordDict.end());
        const size_t s_size(s.size());
        vector<bool> breakable(s_size + 1, false);
        breakable[0] = true;
        for (size_t len = 1; len <= s_size; ++len) {
            for (size_t prelen = 0; prelen < len; ++prelen) {
                if (breakable[prelen] && wordset.count(s.substr(prelen, len - prelen))) {
                    breakable[len] = true;
                    break;
                }
            }
        }
        
        return breakable.back();
    }
};
```


# Knowledge

In computer science, mathematics, management science, economics and bioinformatics, __dynamic programming (also known as dynamic optimization) is a method for solving a complex problem by breaking it down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions__. The next time the same subproblem occurs, instead of recomputing its solution, one simply looks up the previously computed solution, thereby saving computation time at the expense of a (hopefully) modest expenditure in storage space. (Each of the subproblem solutions is indexed in some way, typically based on the values of its input parameters, so as to facilitate its lookup.) The technique of storing solutions to subproblems instead of recomputing them is called __"memoization"__.

__Dynamic programming algorithms are often used for optimization.__ A dynamic programming algorithm will examine the previously solved subproblems and will combine their solutions to give the best solution for the given problem. In comparison, a greedy algorithm treats the solution as some sequence of steps and picks the locally optimal choice at each step. Using a greedy algorithm does not guarantee an optimal solution, because picking locally optimal choices may result in a bad global solution, but it is often faster to calculate. Some greedy algorithms (such as Kruskal's or Prim's for minimum spanning trees) are however proven to lead to the optimal solution.
